from __future__ import division
import os

# Jacob Gold
# Written for Artificial Intelligence, Spring 2013
# Naive Bayes Classifier
# Test data not included as I am not the owner

#The number of instances a feature in test data is assumed to have been seen if not found in the test data
SMOOTHING_FACTOR = .2


MOVIE_KEYWORDS = ["good", "bad", "terrible", "awful", "great", "wonderful", "amazing",
                  "disaster", "interesting", "boring", "fun", "bland"]

class Naive_Bayes(object):
    def __init__(self, data, feature_function):
        """
        Takes a dictionary mapping labels to lists of strings with that label, and a function which
        produces a list of feature values from a string.
        """
        self.training_values = dict()
        """
        A dictionary where each classification corresponds to a pair; a dictionary which maps features
        to the number of times those features appear, and the number of total feature appearances
        """
        for key in data:
            string_list = data[key]
            class_values = dict()
            total = 0
            for string in string_list:
                feature_values = feature_function(string)
                for feature in feature_values:
                    if feature in class_values:
                        class_values[feature] = class_values[feature] + 1
                        total = total + 1
                    else:
                        class_values[feature] = 1 + SMOOTHING_FACTOR
                        total = total + 1 + SMOOTHING_FACTOR
            self.training_values[key] = [class_values, total]
        self.feature_function = feature_function
                


    def classify(self, string):
        """
        Classifies a string according to the feature function and training data
        provided at initialization.
        """
        feature_values = self.feature_function(string)
        class_list = list()
        for key in self.training_values:
            class_list.append([key, 1])
        for feature in feature_values:
            denom_sum = 0
            for classification in class_list:
                d = self.training_values[classification[0]]
                if not feature in d[0]:
                    temp = classification[1] * SMOOTHING_FACTOR / (d[1] + SMOOTHING_FACTOR)
                else:
                    temp = classification[1] * d[0][feature] / d[1] #multiply by the probability of feature being generated by each class
                classification[1] = temp
                denom_sum = temp + denom_sum
            for classification in class_list:
                classification[1] = classification[1] / denom_sum #normalize all probabilities to avoid having them become 0 after many multiplications
        max_prob = class_list[0][1]
        max_class = class_list[0][0]
        for classification in class_list: #find class most likely to have generated string
            if classification[1] > max_prob:
                max_prob = classification[1]
                max_class = classification[0]
        return max_class
                

def load_data(directory):
    """
    Given a pathname of a directory, creates a list of strings out of the
    contents of the files in that directory.
    """
    data_strings=[]
    file_list=os.listdir(directory)
    for filename in file_list:
        pathname=os.path.join(directory,filename)
        data_strings.append(open(pathname).read())
    return data_strings

def print_evaluation(classifier, test_data):
    """
    Takes a classifier and a dictionary mapping labels to lists of test strings.
    Prints accuracy, precision, and recall scores for the classifier.
    """
    scores={}
    correct=0
    total=0
    labels=test_data.keys()
    for label in labels:
        scores[label]={"true_pos":0,"true_neg":0,"false_pos":0,"false_neg":0}
    for label in test_data:
        for string in test_data[label]:
            classification=classifier.classify(string)
            total+=1
            if classification == label:
                correct+=1
                scores[label]["true_pos"]+=1
                for other_label in labels:
                    if other_label != label:
                        scores[other_label]["true_neg"]+=1
            else:
                scores[label]["false_neg"]+=1
                scores[classification]["false_pos"]+=1
                for other_label in labels:
                    if other_label != label and other_label != classification:
                        scores[other_label]["true_neg"]+=1
    print "Accuracy: " + str(correct/total)
    for label in labels:
        true_pos=scores[label]["true_pos"]
        false_pos=scores[label]["false_pos"]
        true_neg=scores[label]["true_neg"]
        false_neg=scores[label]["false_neg"]
        print str(label)
        precision=true_pos/(true_pos+false_pos)
        recall=true_pos/(true_pos+false_neg)
        print "\tPrecision: " + str(precision)
        print "\tRecall: " + str(recall)
        print "\tF-Measure: " + str(2*precision*recall/(precision+recall))

def bag_of_words(string):
    string_list = string.split() #split into words based on white space
    words = list()
    for s in string_list:
        if s.isalpha():
            words.append(s)
        else: #simple attempt to get some punctuation out of the way; NLTK might be better suited for this task
            temp = s
            if not s[0].isalpha():
                temp = temp[1:]
            if not s[len(s) - 1].isalpha():
                temp = temp[:len(s) - 1]
            words.append(temp)
    return words

def keywords(string):
    string_list = string.split()
    words = list()
    for s in string_list:
        temp = s
        if not s.isalpha():
            if not s[0].isalpha():
                temp = temp[1:]
            if not s[len(s) - 1].isalpha():
                temp = temp[:len(s) - 1]
        if temp in MOVIE_KEYWORDS: #only add to list if word is a keyword
            words.append(temp)
    return words

def trigrams(string):
    string_list = string.split()
    tris = list()
    for s in string_list:
        temp = s
        if not s.isalpha():
            if not s[0].isalpha():
                temp = temp[1:]
            if not s[len(s) - 1].isalpha():
                temp = temp[:len(s) - 1]
        for i in range(len(temp) - 2): #add every trigram
            tris.append(temp[i:i+3])
    return tris
    
                


            
            
#Examples of how to use the print_evaluation function. The bag_of_words
#function will need to be written for this to work.
def test():
    movie_train={"pos":load_data("movie_train/pos"),"neg":load_data("movie_test/neg")}
    movie_test={"pos":load_data("movie_test/pos"),"neg":load_data("movie_test/neg")}
    classifier = Naive_Bayes(movie_train,bag_of_words)
    print_evaluation(classifier,movie_test)

def test2():
    movie_train={"pos":load_data("movie_train/pos"),"neg":load_data("movie_test/neg")}
    movie_test={"pos":load_data("movie_test/pos"),"neg":load_data("movie_test/neg")}
    classifier = Naive_Bayes(movie_train,keywords)
    print_evaluation(classifier,movie_test)

def test3():
    twitter_train={"dutch":load_data("twitter_train/dutch"),
                   "english":load_data("twitter_train/english"),
                   "french":load_data("twitter_train/french"),
                   "german":load_data("twitter_train/german"),
                   "italian":load_data("twitter_train/italian"),
                   "spanish":load_data("twitter_train/spanish")}
    twitter_test={"dutch":load_data("twitter_test/dutch"),
                   "english":load_data("twitter_test/english"),
                   "french":load_data("twitter_test/french"),
                   "german":load_data("twitter_test/german"),
                   "italian":load_data("twitter_test/italian"),
                   "spanish":load_data("twitter_test/spanish")}
    classifier = Naive_Bayes(twitter_train,bag_of_words)
    print_evaluation(classifier,twitter_test)

def test4():
    twitter_train={"dutch":load_data("twitter_train/dutch"),
                   "english":load_data("twitter_train/english"),
                   "french":load_data("twitter_train/french"),
                   "german":load_data("twitter_train/german"),
                   "italian":load_data("twitter_train/italian"),
                   "spanish":load_data("twitter_train/spanish")}
    twitter_test={"dutch":load_data("twitter_test/dutch"),
                   "english":load_data("twitter_test/english"),
                   "french":load_data("twitter_test/french"),
                   "german":load_data("twitter_test/german"),
                   "italian":load_data("twitter_test/italian"),
                   "spanish":load_data("twitter_test/spanish")}
    classifier = Naive_Bayes(twitter_train,trigrams)
    print_evaluation(classifier,twitter_test)
            
